{"/":{"title":"Gabriel Chan's website","content":"\nHi, this is my website where I keep my notes for research and class, and maybe projects in the future. \n\n## Content Lists\n- [Research](/notes)\n\n\n\n","lastmodified":"2022-06-22T22:53:08.324070882Z","tags":null},"/notes/back2basics/supervisedlearning":{"title":"Supervised Learning","content":"\n\n# What is supervised learning?\n\n- Training an algorithm to output $y$ for a given $x$ using sufficient training samples $\\{(x^{(0)},y^{(0)}),(x^{(1)},y^{(1)}),\\ldots,(x^{(n)},y^{(n)})\\}$ for some input $x^{(i)}$ and **correct** output $y^{(i)}$ \n- **Regression:** predicting an a number (infinitely many outputs)\n- **Classification:** predicting categories (finite outputs)\n\n\n# Linear Regression \n- Given a training set we can use a learning algorithm to learnign a function $f$ that predicts an output $\\hat{y}$ given an input $x$ \n- for linear regression, $f$ is a straight line. With parameters $w,b$ we can then represent $f$ as: $$f_{w,b}(x)=wx+b$$\n## Cost Function\n- Since our objective to find $w,b$ such taht $\\hat{y}^{(i)}$ is close to $y^{(i)}$ for all $(x^{(i)},y^{(i)})$. \n- Squared error cost function:  $$J(w,b)=\\frac{1}{2m}\\sum^{m}_{i=1}(\\hat{y}^{(i)}-y^{(i)})^2$$\n- where $m=$ number of training examples. So $\\frac{1}{m}$ is to average it so it doesnt blow up, factor of $2$ is for computational convience later. \n- Now we can also rewrite it as: $$J(w,b)=\\frac{1}{2m}\\sum^{m}_{i=1}f_{w,b}(x^{(i)})-y^{(i)})^2$$\n- This can be solved analytically for simple cost functions, but for complicated $J$, we can use gradiant descent to minimize $J$ instead: \n\n## Gradient Descent\n- initialize $w,b$, calcuated $J$ \n- adjust $w,b$ to decrease $J$ \n- repeat until hopefully $J$ settles near minimum \n\n- Step 1: ($=$ here is assignment, not equals)\n$$w=w -\\alpha \\frac{d}{dw}J(w,b)$$ where $\\alpha$ is the learning rate, a **hyperparameter** that controls the \"fast\" we change $w$ \n- Step 2: do the same for $b$ $$b=b -\\alpha \\frac{d}{db}J(w,b)$$\n- **Note:** $w$ and $b$ must be updated at the same time. \n### Learning rate\n- If $\\alpha$ is too small, then it will take many steps to reach minimum \n- If $\\alpha$ is too large, then it might never reach the minimum \n\n# Gradient Descent for linear regression\nCalculating derivatives   for $w$, $$\\frac{d}{dw}J(w,b)= \\frac{d}{dw}\\frac{1}{2m}\\sum^{m}_{i=1}(\\hat{y}^{(i)}-y^{(i)})^2$$$$=\\frac{d}{dw}\\frac{1}{2m}\\sum^{m}_{i=1}(wx^{(i)}+b-y^{(i)})^2$$\nwhich is equal to \n$$\\frac{1}{m}\\sum^{m}_{i=1}(f_{w,b}(x^{(i)}-y^{(i)})x^{(i)}$$\n\nand derivative for $b$, \n$$\\frac{d}{db}J(w,b)= \\frac{d}{dw}\\frac{1}{2m}\\sum^{m}_{i=1}(\\hat{y}^{(i)}-y^{(i)})^2$$$$ =\\frac{d}{db}\\frac{1}{2m}\\sum^{m}_{i=1}(wx^{(i)}+b-y^{(i)})^2$$\nwhich is equal to \n$$\\frac{1}{m}\\sum^{m}_{i=1}(f_{w,b}(x^{(i)})-y^{(i)})$$\n\nPsuedocode for gradient descent:\n```python\nwhile J not converged:\n\tw = w - a * dJdW\n\tb = b- a * dJdb\n```\nwhere `dJdW` = $\\frac{d}{dw}J(w,b)$ and `dJdb` = $\\frac{d}{db}J(w,b)$\n\n\n\n# Multiple features\nwhat if you have multiple features (variables)? \n\n- $x_j = j^{th}$ feature\n- $n$ = number of features\n- $\\vec{x}^{(i)}$= features of $i^{th}$ training example\n- $x_{j}^{(i)}$ = value of feature $j$ in the $i^{th}$ training example\n\nWe can then express the linear regression model as:\n\n$$f_{w,b}(x)=w_1x_1+w_2x_2+\\cdots+w_nx_n+b$$\ndefine $\\vec{w} = [w_1,\\ldots,w_n]$ and $\\vec{x}=[x_1,\\ldots x_n]^T$, $T$ here represents transpose. Then \n$$f_{\\vec{w},b}=\\vec{w}\\cdot \\vec{x}+b$$Where $(\\cdot)$ represents the dot product. \n\n\n\n# Feature Scaling\nWhen the range of values your features can take up differ greatly, i.e. \n- $x_1$ = square footage of house $\\in [500,5000]$ \n- $x_2$ = number of bedrooms $\\in [1,5]$\n\nthis may cause gradient descent to run slowly. ![[notes/images/feature_scaling.png]]\n\nSome examples of feature scaling\n## max scaling\n- divide each data point for a feature by the max value for that feature.\n\n## mean normalization\n- eg: if $300 \\leq x_1 \\leq 2000$ , we can scale it like such $$x_{1new} = \\frac{x_1-\\mu_1}{2000-300}$$\n- where $\\mu_1$ = mean\n\n\n## Z-score normalization \n- find standard deviation $\\sigma$ , mean $\\mu$ then $$x_1=\\frac{x_1-\\mu_1}{\\sigma_1}$$\n\n\n\n\n","lastmodified":"2022-06-22T22:53:08.38007196Z","tags":null},"/notes/back2basics/unsupervisedlearning":{"title":"Unsupervised Learning","content":"\n\n# What is Unsupervised Learning\n\n- no labelled data, algorithm finds something interesting in unlabeled data.\n\t- given only inputs $\\{x_0,\\ldots,x_n\\}$, but no output labels $\\{y_0,\\ldots,y_n\\}$\n- **Clustering:**  for example, groups data points together\n","lastmodified":"2022-06-22T22:53:08.38007196Z","tags":null},"/notes/openPCDet":{"title":"OpenPCDet","content":"# OpenPCDet \n\n## Code Architecture \nfile structure for a project should look something like this:\n\n### Directories\n```bash\nOpenPCDet (or proj name)\n├── data \n│   ├── kitti\n│   ├── lyft\n│   └── waymo\n├── docker\n├── docs\n├── pcdet\n│   ├── datasets\n│   ├── models\n│   ├── ops\n│   └── utils\n└── tools\n    ├── cfgs\n    ├── eval_utils\n    ├── scripts\n    ├── train_utils\n    └── visual_utils\n```\n\n\n\n","lastmodified":"2022-06-22T22:53:08.384072037Z","tags":null},"/notes/papers/3DSSD":{"title":"3DSSD: Point-based 3D Single Stage Object Detector","content":"\n[arXiv link](https://arxiv.org/pdf/2002.10187.pdf) \ngithub #todo \n\n\n## Main Ideas:\n-  Introduced **Feature-Farthest Point Sampling (F-FPS)**\n- Introduced new sampling method called **Fusion Sampling** in [[notes/papers/PointNet++#Set Abstraction SA Layer]]\n\n\n### Feature-Farthest Point Sampling (F-FPS)\n- Objective when downsample: \n\t1. Remove **negative points** (background points) \n\t2. Preserve only **positive points** (foreground points, i.e: points within any instance := ground truth box)\n- Therefore leverage semantic features of points as well when applying FPS \n- Given two points $A$ and $B$, the criterion used to compare them in FPS is:$$C(A,B)=\\lambda L_d(A,B)+L_f(A,B)$$\n\t\twhere \n\t\t- $L_d(A,B)$ is $L^2$ euclidean distance (xyz) \n\t\t- $L_f(A,B)$ is $L^2$ feature distance (distance between the two feature vectors)\n\t\t- $\\lambda$ is chosen parameter, paper seems to choose $\\lambda=1$\n\t\t- *reminder*: $L^2(A,B)= \\sqrt{(B_1-A_1)^2+(B_1-A_1)^2+\\cdots+(B_n-A_n)^2}$  if $A$ and $B$ are $n$ dimensional vectors\n- Result should be a subset of points that are less redundant and more diverse, as points are not only physically distant when sampling, but also in feature space.  \n\n### Fusion Sampling\n- Downsampling to $N_m$ points with **F-FPS** results in:\n\t\t- lots of positive points -\u003e good for regression \n\t\t- few negative points (due to limiting ) -\u003e bad for classification\n\t\t- **Why?** Negative points don't have enough neighbours #expand \n- Input: $N_i\\times C_i :=$ $N$ points each with feature vector of length $C$\n- want to output $N_{i+1}$ points, where $N_{i+1}$ points are subset of the $N_i$ points\n\t1. F-FPS$: N_i \\to \\frac{N_{i+1}}{2}$ #Q\n\t2. D-FPS:$N_i \\to \\frac{N_{i+1}}{2}$ #Q\n\t3. grouping operation ([[notes/papers/PointNet++#Grouping Layer]])\n\t4. MLP\n\t5. MaxPool\n\n![[notes/images/3dssd_backbone.png]]\n#### SA1\n\n$[16384 \\times 4] \\to [4096 \\times 128]$\n\n####  SA2 \n$[4096 \\times 128]\\to [512\\times 256],[512\\times 256]$\n\n\n\n","lastmodified":"2022-06-22T22:53:08.384072037Z","tags":null},"/notes/papers/PointNet++":{"title":"PointNet++","content":"\n\n## Set Abstraction (SA) Layer\n![[notes/images/pointnet2.png]]\n\n### Sampling Layer \nLets call the sampling layer $SL$.\n- Input: $N\\times 3$ \n\t- N points with $x,y,z$\n- Output: $M\\times 3$ \n\t- $M$ points with $x,y,z$ where points in $M$ are subset of $N$\n- Method: **Iterative Farthest Point Sampling** (FPS)\n\t1. Start by choosing 1 random point\n\t2. Calculate distance for all remaining points to selected points.\n\t\t1. so each point will have an array keeping track of the distances \n\t\t3. take the minimum of the arrray, i.e. for each remaining point, set its distance to the closest selected point.\n\t\t4. Finally, select the point with the greatest distance\n\t3. Repeat step 2 $M-1$ more times\n\t- **1D Example:** Consider an array of points $P=[1,6,7,8,20]$, \n\t\t1. suppose the list of selected points $S=[7,20]$ , $P$ is now $[1,6,8]$\n\t\t2. we calculate distances:\n\t\t   $$\\begin{align*}dist_1=[6,19]\\\\\n\t\t   dist_6=[1,14]\\\\\n\t\t   dist_8=[1,12]\\\\\n\t\t   \\end{align*}$$\n\t\t3. perform $min (dist_i)$$$\\begin{align*}dist_1=6\\\\\n\t\t   dist_6=1\\\\\n\t\t   dist_8=1\\\\\n\t\t   \\end{align*}$$\n\t\t4. now select the point with highest distance. i.e. $$\\underset{i}{\\operatorname{argmax}}(dist_i)=1$$\n\t\t5. So the next chosen point is 1. $S=[1,7,20]$ and $P=[6,8]$\n\n\n\n### Grouping Layer\n- Sampling Layer $SL$ yields $N'\\times 3$ points.\n\t- $N'$ centroids and $3:= x,y,z$ coordinates \n\t- $SL:(N\\times 3) \\to (N'\\times 3)$\n- Input: \n\t- $(N\\times 3+ C)$: points before sampling and their feature vectors of len $C$\n\t-  $(N'\\times d)$: predicted centroids \n- Output: \n\t- $(N'\\times K \\times (3+C))$: centroid + $K$ points within radius of $r$ along their features\n- Method: \n\t- Ball query\n\t\t\t- what if points within radius is $\u003cK$? \n\t\t\t- what if no points (only centroid point)?\n\t\t\t- with if more than $K$ points?  \n\n#### Multi-scale grouping (MSG)\n- Due to nonuniformity of point clouds, we needs some more tricks to make feature learning more robust. \n- One simple way is to applying grouping + pointnet multiple times then concat their features \n![[notes/images/msg.png]]\n\n\n#### Multi-resolution grouping (MRG)\n- MSG works, but its computationally expensive, so this is an alternative method \n- Consider a layer for input of points, we first apply set abstraction layer (sampling + grouping + pointnet), to yield a vector of features $L_1$. We then  apply pointnet of the raw pointcloud (before set abstraction) to yield feature vector $L_2$. Then we concat the results $(L_1,L_2)$ \n\n![[notes/images/mrg.png]]\n### PointNet Layer\nessentially just a FC layer on each \"ball\" of points\n- Input $(N'\\times K \\times (3+C))$.\n\t- $N'$ local regions (balls of points)\n\t- $K$ is num of balls in the ball\n\t- $3+C = x,y,z+C \\text{ features}$\n- Output: $(N'\\times (3+C'))$ \n- Method: \n\t- for each point $x_j$ in a ball, transform it into a local coordinate frame relative to its centroid $\\hat{x}$ $$x^{new}_j = x_j-\\hat{x}$$\n\n","lastmodified":"2022-06-22T22:53:08.384072037Z","tags":null},"/tags/setup":{"title":"","content":"","lastmodified":"2022-06-22T22:53:08.384072037Z","tags":null}}